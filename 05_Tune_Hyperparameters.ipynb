{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=modified_huber, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=modified_huber, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=modified_huber, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=modified_huber, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=modified_huber, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=hinge, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=hinge, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=hinge, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=hinge, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=hinge, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.6, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=  12.6s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.6, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   9.5s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.6, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=  10.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.6, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   7.8s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.6, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=  12.7s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=constant, loss=squared_hinge, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=constant, loss=squared_hinge, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=constant, loss=squared_hinge, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=constant, loss=squared_hinge, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=constant, loss=squared_hinge, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=optimal, loss=perceptron, max_iter=3000, penalty=elasticnet; total time=   3.3s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=optimal, loss=perceptron, max_iter=3000, penalty=elasticnet; total time=   3.9s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=optimal, loss=perceptron, max_iter=3000, penalty=elasticnet; total time=   3.2s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=optimal, loss=perceptron, max_iter=3000, penalty=elasticnet; total time=   3.4s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.7, learning_rate=optimal, loss=perceptron, max_iter=3000, penalty=elasticnet; total time=   4.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.3, learning_rate=constant, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.3, learning_rate=constant, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.3, learning_rate=constant, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.3, learning_rate=constant, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.3, learning_rate=constant, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.2, learning_rate=constant, loss=log_loss, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.2, learning_rate=constant, loss=log_loss, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.2, learning_rate=constant, loss=log_loss, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.2, learning_rate=constant, loss=log_loss, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.2, learning_rate=constant, loss=log_loss, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=optimal, loss=hinge, max_iter=1500, penalty=l2; total time=  11.6s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=optimal, loss=hinge, max_iter=1500, penalty=l2; total time=   9.5s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=optimal, loss=hinge, max_iter=1500, penalty=l2; total time=   5.9s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=optimal, loss=hinge, max_iter=1500, penalty=l2; total time=   8.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=optimal, loss=hinge, max_iter=1500, penalty=l2; total time=   9.5s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.2, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.2, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.2, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.2, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.2, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.4, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.4, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.4, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.4, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.4, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.3, learning_rate=optimal, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   4.5s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.3, learning_rate=optimal, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   5.2s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.3, learning_rate=optimal, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   6.8s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.3, learning_rate=optimal, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   4.7s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.3, learning_rate=optimal, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   5.8s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.15, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.15, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.15, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.15, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.15, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.3, learning_rate=optimal, loss=hinge, max_iter=1500, penalty=l2; total time=   7.6s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.3, learning_rate=optimal, loss=hinge, max_iter=1500, penalty=l2; total time=   9.4s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.3, learning_rate=optimal, loss=hinge, max_iter=1500, penalty=l2; total time=   7.9s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.3, learning_rate=optimal, loss=hinge, max_iter=1500, penalty=l2; total time=   7.8s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.3, learning_rate=optimal, loss=hinge, max_iter=1500, penalty=l2; total time=   8.1s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.4, learning_rate=constant, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.4, learning_rate=constant, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.4, learning_rate=constant, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.4, learning_rate=constant, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.4, learning_rate=constant, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=  16.3s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=  12.7s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=  13.3s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=  12.1s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=  14.7s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.6, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.1, learning_rate=adaptive, loss=log_loss, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.1, learning_rate=adaptive, loss=log_loss, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.1, learning_rate=adaptive, loss=log_loss, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.1, learning_rate=adaptive, loss=log_loss, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.1, learning_rate=adaptive, loss=log_loss, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.7, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.7, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.7, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.7, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.7, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.15, learning_rate=invscaling, loss=log_loss, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.15, learning_rate=invscaling, loss=log_loss, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.15, learning_rate=invscaling, loss=log_loss, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.15, learning_rate=invscaling, loss=log_loss, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.15, learning_rate=invscaling, loss=log_loss, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.15, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.15, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.15, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.15, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.15, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.5, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.5, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.5, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.5, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.5, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.4, learning_rate=invscaling, loss=perceptron, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.4, learning_rate=invscaling, loss=perceptron, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.4, learning_rate=invscaling, loss=perceptron, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.4, learning_rate=invscaling, loss=perceptron, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.4, learning_rate=invscaling, loss=perceptron, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.3, learning_rate=adaptive, loss=hinge, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.3, learning_rate=adaptive, loss=hinge, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.3, learning_rate=adaptive, loss=hinge, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.3, learning_rate=adaptive, loss=hinge, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.3, learning_rate=adaptive, loss=hinge, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.4, learning_rate=invscaling, loss=squared_hinge, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.4, learning_rate=invscaling, loss=squared_hinge, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.4, learning_rate=invscaling, loss=squared_hinge, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.4, learning_rate=invscaling, loss=squared_hinge, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.4, learning_rate=invscaling, loss=squared_hinge, max_iter=1500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.5, learning_rate=invscaling, loss=log_loss, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.5, learning_rate=invscaling, loss=log_loss, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.5, learning_rate=invscaling, loss=log_loss, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.5, learning_rate=invscaling, loss=log_loss, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.5, learning_rate=invscaling, loss=log_loss, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.5, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.5, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.5, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.5, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.5, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.5, learning_rate=invscaling, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.5, learning_rate=invscaling, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.5, learning_rate=invscaling, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.5, learning_rate=invscaling, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.5, learning_rate=invscaling, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.2, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.2, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.2, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.2, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.2, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.7, learning_rate=adaptive, loss=perceptron, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.7, learning_rate=adaptive, loss=perceptron, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.7, learning_rate=adaptive, loss=perceptron, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.7, learning_rate=adaptive, loss=perceptron, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.7, learning_rate=adaptive, loss=perceptron, max_iter=2500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=constant, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=constant, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=constant, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=constant, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.2, learning_rate=constant, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.5, learning_rate=optimal, loss=hinge, max_iter=2500, penalty=l2; total time=   6.5s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.5, learning_rate=optimal, loss=hinge, max_iter=2500, penalty=l2; total time=   7.1s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.5, learning_rate=optimal, loss=hinge, max_iter=2500, penalty=l2; total time=   7.2s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.5, learning_rate=optimal, loss=hinge, max_iter=2500, penalty=l2; total time=   7.5s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.5, learning_rate=optimal, loss=hinge, max_iter=2500, penalty=l2; total time=   6.7s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.6, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.1, learning_rate=invscaling, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.1, learning_rate=invscaling, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.1, learning_rate=invscaling, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.1, learning_rate=invscaling, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.1, learning_rate=invscaling, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.1, learning_rate=constant, loss=log_loss, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.1, learning_rate=constant, loss=log_loss, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.1, learning_rate=constant, loss=log_loss, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.1, learning_rate=constant, loss=log_loss, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.1, learning_rate=constant, loss=log_loss, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.5, learning_rate=adaptive, loss=hinge, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.5, learning_rate=adaptive, loss=hinge, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.5, learning_rate=adaptive, loss=hinge, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.5, learning_rate=adaptive, loss=hinge, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=True, l1_ratio=0.5, learning_rate=adaptive, loss=hinge, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.7, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.4, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.4, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.4, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.4, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.4, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.5, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.5, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.5, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.5, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.5, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.2, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.2, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.2, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.2, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=False, l1_ratio=0.2, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=constant, loss=log_loss, max_iter=1500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.3, learning_rate=adaptive, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.3, learning_rate=adaptive, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.3, learning_rate=adaptive, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.3, learning_rate=adaptive, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-06, fit_intercept=False, l1_ratio=0.3, learning_rate=adaptive, loss=modified_huber, max_iter=2500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=optimal, loss=hinge, max_iter=2500, penalty=elasticnet; total time=   5.2s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=optimal, loss=hinge, max_iter=2500, penalty=elasticnet; total time=   5.5s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=optimal, loss=hinge, max_iter=2500, penalty=elasticnet; total time=   5.9s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=optimal, loss=hinge, max_iter=2500, penalty=elasticnet; total time=   5.5s\n",
      "[CV] END alpha=1e-05, fit_intercept=True, l1_ratio=0.3, learning_rate=optimal, loss=hinge, max_iter=2500, penalty=elasticnet; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s210930\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "210 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "210 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\s210930\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\s210930\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\s210930\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 905, in fit\n",
      "    self._more_validate_params()\n",
      "  File \"C:\\Users\\s210930\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 153, in _more_validate_params\n",
      "    raise ValueError(\"eta0 must be > 0\")\n",
      "ValueError: eta0 must be > 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\s210930\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.69654503        nan 0.57904459\n",
      "        nan        nan 0.61938475        nan        nan        nan\n",
      " 0.67386092        nan        nan        nan        nan 0.65991232\n",
      "        nan        nan 0.64477689        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.66614997        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.65614271]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=SGDClassifier(), n_iter=50,\n",
       "                   param_distributions={&#x27;alpha&#x27;: (1e-05, 1e-06),\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;l1_ratio&#x27;: [0.1, 0.15, 0.2, 0.3, 0.4,\n",
       "                                                     0.5, 0.6, 0.7],\n",
       "                                        &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;optimal&#x27;,\n",
       "                                                          &#x27;invscaling&#x27;,\n",
       "                                                          &#x27;adaptive&#x27;],\n",
       "                                        &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;,\n",
       "                                                 &#x27;modified_huber&#x27;,\n",
       "                                                 &#x27;squared_hinge&#x27;,\n",
       "                                                 &#x27;perceptron&#x27;],\n",
       "                                        &#x27;max_iter&#x27;: [1000, 1500, 2000, 2500,\n",
       "                                                     3000],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;elasticnet&#x27;]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=SGDClassifier(), n_iter=50,\n",
       "                   param_distributions={&#x27;alpha&#x27;: (1e-05, 1e-06),\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;l1_ratio&#x27;: [0.1, 0.15, 0.2, 0.3, 0.4,\n",
       "                                                     0.5, 0.6, 0.7],\n",
       "                                        &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;optimal&#x27;,\n",
       "                                                          &#x27;invscaling&#x27;,\n",
       "                                                          &#x27;adaptive&#x27;],\n",
       "                                        &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;,\n",
       "                                                 &#x27;modified_huber&#x27;,\n",
       "                                                 &#x27;squared_hinge&#x27;,\n",
       "                                                 &#x27;perceptron&#x27;],\n",
       "                                        &#x27;max_iter&#x27;: [1000, 1500, 2000, 2500,\n",
       "                                                     3000],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;elasticnet&#x27;]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=SGDClassifier(), n_iter=50,\n",
       "                   param_distributions={'alpha': (1e-05, 1e-06),\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'l1_ratio': [0.1, 0.15, 0.2, 0.3, 0.4,\n",
       "                                                     0.5, 0.6, 0.7],\n",
       "                                        'learning_rate': ['constant', 'optimal',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'loss': ['hinge', 'log_loss',\n",
       "                                                 'modified_huber',\n",
       "                                                 'squared_hinge',\n",
       "                                                 'perceptron'],\n",
       "                                        'max_iter': [1000, 1500, 2000, 2500,\n",
       "                                                     3000],\n",
       "                                        'penalty': ['l2', 'elasticnet']},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %store -r X_resampled\n",
    "# %store -r y_resampled\n",
    "# grid = {\"l1_ratio\":[0.1,0.15,0.2,0.3, 0.4,0.5,0.6,0.7],\n",
    "#         \"fit_intercept\":[True,False],\n",
    "#         \"max_iter\":[1000,1500,2000,2500,3000],\n",
    "#         \"learning_rate\":['constant',\"optimal\",\"invscaling\",\"adaptive\"],\n",
    "#         \"loss\":[\"hinge\",\"log_loss\",\"modified_huber\",\"squared_hinge\",\"perceptron\"],\n",
    "#         \"alpha\": (0.00001, 0.000001),\n",
    "#         \"penalty\":[\"l2\",\"elasticnet\"]\n",
    "#         }\n",
    "# np.random.seed(1)\n",
    "# X_train, X_test,y_train,y_test = train_test_split(X_resampled,y_resampled)\n",
    "# SDG_clf = SGDClassifier()\n",
    "# rs_sdg_clf = RandomizedSearchCV(estimator=SDG_clf,param_distributions=grid,n_iter=50,verbose=2)\n",
    "\n",
    "# rs_sdg_clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608964811022156\n",
      "[[19758  1638]\n",
      " [15164  6408]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2a1c504c610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_pred=rs_sdg_clf.predict(X_test)\n",
    "# print(rs_sdg_clf.score(X_test,y_test))\n",
    "# cm = confusion_matrix(y_test,y_pred)\n",
    "# print(cm)\n",
    "# display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "# display.plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
